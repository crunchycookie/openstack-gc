diff --git a/nova/conf/compute.py b/nova/conf/compute.py
index c825b73d94..de2743d850 100644
--- a/nova/conf/compute.py
+++ b/nova/conf/compute.py
@@ -878,26 +878,7 @@ Related options:
   where ``VCPU`` resources should be allocated from.
 * ``vcpu_pin_set``: A legacy option that this option partially replaces.
 """),
-   cfg.StrOpt('cpu_high_priority_set',
-        help="""
-Mask of host CPUs that can be used for prioritized ``PCPU`` resources.
-
-Possible values:
-
-* A comma-separated list of physical CPU numbers that instance VCPUs can be
-  allocated from. Each element should be either a single CPU number, a range of
-  CPU numbers, or a caret followed by a CPU number to be excluded from a
-  previous range. For example::
-
-    cpu_dedicated_set = "4-12,^8,15"
-
-Related options:
-
-* ``[compute] cpu_dedicated_set``: This is the parent option for defining the superset
-  where ``VCPU`` resources should be allocated from. ``[compute] cpu_high_priority_set`` option complements 
-  this option by enabling physical CPU prioritization.
-"""),
-   cfg.BoolOpt('live_migration_wait_for_vif_plug',
+    cfg.BoolOpt('live_migration_wait_for_vif_plug',
         default=True,
         help="""
 Determine if the source compute host should wait for a ``network-vif-plugged``
diff --git a/nova/virt/hardware.py b/nova/virt/hardware.py
index 018072247b..a8733796ef 100644
--- a/nova/virt/hardware.py
+++ b/nova/virt/hardware.py
@@ -76,22 +76,6 @@ def get_cpu_dedicated_set():
     return cpu_ids
 
 
-def get_cpu_high_priority_set():
-    """Parse ``[compute] cpu_high_priority_set`` config.
-
-    :returns: A set of host CPU IDs that can be used for prioritized PCPU allocations.
-    """
-    if not CONF.compute.cpu_high_priority_set:
-        return None
-
-    cpu_ids = parse_cpu_spec(CONF.compute.cpu_high_priority_set)
-    if not cpu_ids:
-        msg = _("No CPUs available after parsing '[compute] "
-                "cpu_high_priority_set' config, %r")
-        raise exception.Invalid(msg % CONF.compute.cpu_high_priority_set)
-    return cpu_ids
-
-
 def get_cpu_dedicated_set_nozero():
     """Return cpu_dedicated_set without CPU0, if present"""
     return (get_cpu_dedicated_set() or set()) - {0}
@@ -736,30 +720,8 @@ def _pack_instance_onto_cores(host_cell, instance_cell,
         #
         # For an instance_cores=[2, 3], usable_cores=[[0], [4]]
         # vcpus_pinning=[(2, 0), (3, 4)]
-
-        # todo  Tharindu: Below is PoC implementation, and not efficient at all.
-        def get_priority_weight(val, high_p_list):
-            if val in high_p_list:
-                return 0
-            return 1
-
-        # todo: properly inject this through conf file: high_priority_cores = get_cpu_high_priority_set()
-        high_priority_cores = [0, 1, 2]
-        usable_cores_list = list(itertools.chain(*usable_cores))
-        if len(high_priority_cores) > 1:
-            usable_cores_list = sorted(usable_cores_list, key=lambda x: get_priority_weight(x, high_priority_cores))
-            msg = ("Using priority core pinning: high priority cores: "
-                   "%(high_priority_cores)s, priority ordered host cores: %(usable_cores_list)s")
-            msg_args = {
-                'high_priority_cores': high_priority_cores,
-                'usable_cores_list': usable_cores_list,
-            }
-            LOG.info(msg, msg_args)
-        vcpus_pinning = list(zip(
-            sorted(instance_cores),
-            usable_cores_list
-        ))
-
+        vcpus_pinning = list(zip(sorted(instance_cores),
+                                 itertools.chain(*usable_cores)))
         msg = ("Computed NUMA topology CPU pinning: usable pCPUs: "
                "%(usable_cores)s, vCPUs mapping: %(vcpus_pinning)s")
         msg_args = {
@@ -767,8 +729,6 @@ def _pack_instance_onto_cores(host_cell, instance_cell,
             'vcpus_pinning': vcpus_pinning,
         }
         LOG.info(msg, msg_args)
-        # In the prototype: Allocate vm with pinnning enabled + number of cores = 1
-        # Computed NUMA topology CPU pinning: usable pCPUs: [[0], [1], [2], [3]], vCPUs mapping: [(0, 0)]
 
         return vcpus_pinning
 
diff --git a/nova/virt/libvirt/host.py b/nova/virt/libvirt/host.py
index 2dfc1bfcbc..b57751093e 100644
--- a/nova/virt/libvirt/host.py
+++ b/nova/virt/libvirt/host.py
@@ -38,7 +38,6 @@ import queue
 import socket
 import threading
 import typing as ty
-import requests as rq
 
 from eventlet import greenio
 from eventlet import greenthread
@@ -761,28 +760,7 @@ class Host(object):
             if cpu_map[cpu]:
                 online_cpus.add(cpu)
 
-        asleep_cpus = self._get_sleeping_cpus()
-        os_online_cpus = online_cpus - asleep_cpus
-        if len(asleep_cpus) > 0:
-            LOG.info('Asleep cpus detected. %(libvirsh_online_cpus)s:%(asleep_cpus)s for '
-                     'os_online %(os_online_cpus)s',
-                     {'libvirsh_online_cpus': online_cpus, 'asleep_cpus': asleep_cpus,
-                      'os_online_cpus': os_online_cpus})
-
-        return os_online_cpus
-
-    def _get_sleeping_cpus(self):
-        """Get the ids of the cores that are sleeping.
-
-        :returns: list of ids that are asleep.
-        """
-        # todo hardcoded:: supports only a single green core which has an id of 3.
-        r = rq.get(url="http://100.70.12.103:4000/gc/is-asleep")
-        data = r.json()
-        is_awake = data['is-awake']
-
-        sleeping_cpus = set() if is_awake else {3}
-        return sleeping_cpus
+        return online_cpus
 
     def get_cpu_model_names(self):
         """Get the cpu models based on host CPU arch
